# nnUNet_Trans
This ensemble approach is developed for brain tumor segmentation.
The paper 'Ensemble Learning with Residual Transformer for Brain Tumor Segmentation' is accepted for ISBI. (link: TBD)

Brain tumor segmentation is an active research area due to the difficulty in delineating highly complex shaped and textured tumors as well as the failure of the commonly used U-Net architectures in such. The combination of different neural architectures is among the mainstream research recently, particularly the combination of U-Net with Transformers because of their innate attention mechanism and pixel-wise labeling. Different from previous efforts, this paper proposed a novel network architecture that integrates Transformers into a self-adaptive U-Net to draw out 3D volumetric contexts with reasonable computational costs. We further added residual connection to prevent degradation in information flow and explored ensemble methods, as the evaluated models have edges on different cases and sub-regions. On the BraTS 2021 dataset (3D), our models outperformed state-of-the-art segmentation methods. Our findings may direct future research on potential ways of combining multiple architectures and their fusions for optimal segmentation of brain tumors.

Four models are applied: 

  E1D3, 

  nnUNet, 

  nnUNet+transformer (BraTS22_nnUNet+Trans/nnUNet/nnunet/training/network_training/nnTransUNetTrainerV2.py), 
  
  nnUNet+residual transformer (BraTS22_nnUNet+Trans/nnUNet/nnunet/training/network_training/nnTransResUNetTrainerV2.py).

Inferences generated by each model are then combined as mode, median, average and threshold. For the threshold ensemble, we set a threshold of TC volume smaller than 60 and ET volume larger than 60 to automatically select subjects to be predicted by E1D3 model, and the rest subjects use the UNet+T model. This is based on the observation that E1D3 performs better at subjects with these criteria, which may suggest there are fewer than four labels in the ground truth. We observe that the threshold method shows the best overall performance, in both Dice score and HD, suggesting that this criterion helps to improve our models. 
